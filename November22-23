import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
try:
	import statsmodels.api as sm
except Exception:
	sm = None
	warnings.warn("statsmodels is not installed; continuing without it")

from scipy import stats
from scipy.stats import ttest_1samp
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats.mstats import winsorize
from scipy.stats import boxcox
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import Lasso, Ridge, ElasticNet

df=pd.read_csv('tvmarketing.csv')
print(df)
print(df.info())
print(df.describe())
#df.plot()
df.isnull().sum()

df.shape
(200,2)

x = df[['TV']]
y = df[['Sales']]


x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)
print(x_train)
print(x_test)
print("==========================================")
print(y_train)


lr = LinearRegression()
lr.fit(x_train, y_train)


plt.scatter(x_test, y_test, color='red')
plt.plot(x_train, lr.predict(x_train), color='blue')
plt.xlabel('TV')
plt.ylabel('Sales')
plt.title('TV vs Sales - Lenear Regression')
#plt.show()


y_pred = lr.predict(x_test)
r2 = r2_score(y_test, y_pred)
print("==========================================")
print("R² Score on Test Set:", r2*100)

mae = mean_absolute_error(y_test, y_pred)
print("==========================================")
print("Mean Absolute Error on Test Set:", mae)

mse = mean_squared_error(y_test, y_pred)
print("==========================================")
print("Mean Squared Error on Test Set:", mse)

rmse = np.sqrt(mse)
print("==========================================")
print("Root Mean Squared Error on Test Set:", rmse)

y_train_predict = lr.predict(x_train)
y_test_predict = lr.predict(x_test)

r2_train = r2_score(y_train, y_train_predict)
r2_test = r2_score(y_test, y_test_predict)

mae_train = mean_absolute_error(y_train, y_train_predict)
mae_test = mean_absolute_error(y_test, y_test_predict)

mse_train = mean_squared_error(y_train, y_train_predict)
mse_test = mean_squared_error(y_test, y_test_predict)

print("==========================================")
print("Training Set Mean Absolute Error:", mae_train)
print("Test Set Mean Absolute Error:", mae_test)
print("==========================================")
print("Training Set Mean Squared Error:", mse_train)
print("Test Set Mean Squared Error:", mse_test)
print("==========================================")
print("Training Set R² Score:", r2_train)
print("Test Set R² Score:", r2_test)

print("==========================================")
if mse_train < mse_test or r2_train > r2_test:
	if abs(r2_train - r2_test) > 0.1:
		print("The model may be overfitting to the training data.")
	else:
		print("The model is performing well but check for slight overfitting.")
elif mse_train > mse_test or r2_train < r2_test:
		print("The model may be underfitting consider increasing model complexity.")
else:
		print("Model has a balanced fit on both training and testing dataset.")
print("==========================================")

lr.fit(x_train, y_train)
y_predict = lr.predict(x_test)
r2 = r2_score(y_test, y_predict)
print("R² Score after re-fitting on Test Set:", r2*100)
print("==========================================")

lasso = Lasso()
lasso.fit(x_train, y_train)
y_lasso_pred = lasso.predict(x_test)
r2_lasso = r2_score(y_test, y_lasso_pred)
print("Lasso Predict : ", r2_lasso*100)
print("==========================================")


ridge = Ridge()
ridge.fit(x_train, y_train)
y_ridge_predict = ridge.predict(x_test)
r2_ridge = r2_score(y_test, y_ridge_predict)
print("Ridge Predict : ", r2_ridge*100)
print("==========================================")


elastic = ElasticNet()
elastic.fit(x_train, y_train)
y_elastic_predict = elastic.predict(x_test)
r2_elastic = r2_score(y_test, y_elastic_predict)
print("ElasticNet Predict : ", r2_elastic*100)
print("==========================================")

print("All model evaluations complete.")
print("==========================================")

prdict_229 = lr.predict([[229.5]])
print("Predicted sales for TV advertising budget of 229:", prdict_229)
print("==========================================")

predict_229_lasso = lasso.predict([[229.5]])
print("Lasso Predicted sales for TV advertising budget of 229:", predict_229_lasso)
print("==========================================")

predict_229_ridge = ridge.predict([[229.5]])
print("Ridge Predicted sales for TV advertising budget of 229:", predict_229_ridge)
print("==========================================")

predict_229_elastic = elastic.predict([[229.5]])
print("ElasticNet Predicted sales for TV advertising budget of 229:", predict_229_elastic)
print("==========================================")

print("Model predictions complete.")
print("=====================NON-LINEAR REGRESSION - POLYNOMIAL=====================")

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline

# Polynomial regression (degree 2, 3, 4)
# for degree in [2, 3, 4]:
#     # Create pipeline: polynomial features -> linear regression
#     poly_pipeline = Pipeline([
#         ('poly_features', PolynomialFeatures(degree=degree, include_bias=False)),
#         ('linear_regression', LinearRegression())
#     ])
    
#     # Fit on training data
#     poly_pipeline.fit(x_train, y_train)
    
#     # Predict on test data
#     y_poly_pred = poly_pipeline.predict(x_test)
    
#     # Evaluate
#     r2_poly = r2_score(y_test, y_poly_pred)
#     mse_poly = mean_squared_error(y_test, y_poly_pred)
#     rmse_poly = np.sqrt(mse_poly)
#     mae_poly = mean_absolute_error(y_test, y_poly_pred)
    
#     print(f"Polynomial Degree {degree}:")
#     print(f"  R² Score: {r2_poly*100:.2f}%")
#     print(f"  MAE: {mae_poly:.4f}")
#     print(f"  MSE: {mse_poly:.4f}")
#     print(f"  RMSE: {rmse_poly:.4f}")
    
#     # Predict for TV budget of 229.5
#     pred_229_poly = poly_pipeline.predict([[229.5]])
#     print(f"  Predicted sales for TV=229.5: {pred_229_poly[0][0]:.2f}")
#     print("==========================================")

# # Visualize: Linear vs Polynomial fits
# x_range = np.linspace(x_train.min(), x_train.max(), 100).reshape(-1, 1)

# plt.figure(figsize=(12, 4))

# # Plot 1: Linear
# plt.subplot(1, 3, 1)
# plt.scatter(x_test, y_test, color='red', alpha=0.5, label='Test data')
# plt.plot(x_range, lr.predict(x_range), color='blue', linewidth=2, label='Linear')
# plt.xlabel('TV')
# plt.ylabel('Sales')
# plt.title('Linear Regression')
# plt.legend()

# # Plot 2: Polynomial degree 2
# plt.subplot(1, 3, 2)
# poly2_pipeline = Pipeline([
#     ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),
#     ('linear_regression', LinearRegression())
# ])
# poly2_pipeline.fit(x_train, y_train)
# plt.scatter(x_test, y_test, color='red', alpha=0.5, label='Test data')
# plt.plot(x_range, poly2_pipeline.predict(x_range), color='green', linewidth=2, label='Poly degree 2')
# plt.xlabel('TV')
# plt.ylabel('Sales')
# plt.title('Polynomial Regression (degree 2)')
# plt.legend()

# # Plot 3: Polynomial degree 3
# plt.subplot(1, 3, 3)
# poly3_pipeline = Pipeline([
#     ('poly_features', PolynomialFeatures(degree=3, include_bias=False)),
#     ('linear_regression', LinearRegression())
# ])
# poly3_pipeline.fit(x_train, y_train)
# plt.scatter(x_test, y_test, color='red', alpha=0.5, label='Test data')
# plt.plot(x_range, poly3_pipeline.predict(x_range), color='orange', linewidth=2, label='Poly degree 3')
# plt.xlabel('TV')
# plt.ylabel('Sales')
# plt.title('Polynomial Regression (degree 3)')
# plt.legend()

# plt.tight_layout()
# plt.savefig('polynomial_regression_comparison.png')
# plt.show()

# print("Polynomial regression analysis complete.")
# print("Plot saved: polynomial_regression_comparison.png")

poly_features = PolynomialFeatures()
x_train_poly = poly_features.fit_transform(x_train)
x_test_poly = poly_features.transform(x_test)

poly_model = LinearRegression()
poly_model.fit(x_train_poly, y_train)

y_poly_pred = poly_model.predict(x_test_poly)
y_train_poly = poly_model.predict(x_train_poly)

r2_poly_train = r2_score(y_train, y_train_poly)
print("R2 Score on Train Set (Polynomial):", r2_poly_train*100)

polly_predict = poly_model.predict(poly_features.transform([[229.5]]))
print("Predicted sales for TV advertising budget of 229 (Polynomial):", polly_predict)
print("==========================================")

x_range = np.linspace(x_train.min(), x_train.max(), 100).reshape(-1, 1)
plt.scatter(x_test, y_test, color='red')
plt.plot(x_range, poly_model.predict(poly_features.transform(x_range)), color='blue')
plt.xlabel('TV')
plt.ylabel('Sales')
plt.title('TV vs Sales - Polynomial Regression')
plt.show() 

