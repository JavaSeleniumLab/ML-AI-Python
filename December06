import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
try:
	import statsmodels.api as sm
except Exception:
	sm = None
	warnings.warn("statsmodels is not installed; continuing without it")

from scipy import stats
from scipy.stats import ttest_1samp
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats.mstats import winsorize
from scipy.stats import boxcox
from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score, train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.linear_model import Lasso, Ridge, ElasticNet
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, auc, roc_curve)

df=pd.read_csv('housing_with_ocean_proximity.csv')
print(df)
print(df.info())
print(df.describe())
#df.plot()
df.isnull().sum()

x = df[['median_income']]
y = df[['median_house_value']]


x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)
print(x_train)
print(x_test)
print("==========================================")
print(y_train)


lr = LinearRegression()
lr.fit(x_train, y_train)


plt.scatter(x_test, y_test, color='red')
plt.plot(x_train, lr.predict(x_train), color='blue')
plt.xlabel('Median Income')
plt.ylabel('Median House Value')
plt.title('Median Income and Median House Value - Lenear Regression')
#plt.show()


y_pred = lr.predict(x_test)
r2 = r2_score(y_test, y_pred)
print("==========================================")
print("R² Score on Test Set:", r2*100)

mae = mean_absolute_error(y_test, y_pred)
print("==========================================")
print("Mean Absolute Error on Test Set:", mae)

mse = mean_squared_error(y_test, y_pred)
print("==========================================")
print("Mean Squared Error on Test Set:", mse)

rmse = np.sqrt(mse)
print("==========================================")
print("Root Mean Squared Error on Test Set:", rmse)

y_train_predict = lr.predict(x_train)
y_test_predict = lr.predict(x_test)

r2_train = r2_score(y_train, y_train_predict)
r2_test = r2_score(y_test, y_test_predict)

mae_train = mean_absolute_error(y_train, y_train_predict)
mae_test = mean_absolute_error(y_test, y_test_predict)

mse_train = mean_squared_error(y_train, y_train_predict)
mse_test = mean_squared_error(y_test, y_test_predict)

print("==========================================")
print("Training Set Mean Absolute Error:", mae_train)
print("Test Set Mean Absolute Error:", mae_test)
print("==========================================")
print("Training Set Mean Squared Error:", mse_train)
print("Test Set Mean Squared Error:", mse_test)
print("==========================================")
print("Training Set R² Score:", r2_train)
print("Test Set R² Score:", r2_test)

print("==========================================")
if mse_train < mse_test or r2_train > r2_test:
	if abs(r2_train - r2_test) > 0.1:
		print("The model may be overfitting to the training data.")
	else:
		print("The model is performing well but check for slight overfitting.")
elif mse_train > mse_test or r2_train < r2_test:
		print("The model may be underfitting consider increasing model complexity.")
else:
		print("Model has a balanced fit on both training and testing dataset.")
print("==========================================")

lr.fit(x_train, y_train)
y_predict = lr.predict(x_test)
r2 = r2_score(y_test, y_predict)
print("R² Score after re-fitting on Test Set:", r2*100)
print("==========================================")

lasso = Lasso()
lasso.fit(x_train, y_train)
y_lasso_pred = lasso.predict(x_test)
r2_lasso = r2_score(y_test, y_lasso_pred)
print("Lasso Predict : ", r2_lasso*100)
print("==========================================")


ridge = Ridge()
ridge.fit(x_train, y_train)
y_ridge_predict = ridge.predict(x_test)
r2_ridge = r2_score(y_test, y_ridge_predict)
print("Ridge Predict : ", r2_ridge*100)
print("==========================================")


elastic = ElasticNet()
elastic.fit(x_train, y_train)
y_elastic_predict = elastic.predict(x_test)
r2_elastic = r2_score(y_test, y_elastic_predict)
print("ElasticNet Predict : ", r2_elastic*100)
print("==========================================")

print("All model evaluations complete.")
print("==========================================")

prdict_229 = lr.predict([[10]])
print("Predicted for:", prdict_229)
print("==========================================")

predict_229_lasso = lasso.predict([[10]])
print("Lasso Predicted for :", predict_229_lasso)
print("==========================================")

predict_229_ridge = ridge.predict([[10]])
print("Ridge Predicted for :", predict_229_ridge)
print("==========================================")

predict_229_elastic = elastic.predict([[10]])
print("ElasticNet Predicted for:", predict_229_elastic)
print("==========================================")

print("Model predictions complete.")


kf = KFold(n_splits=5, shuffle=True, random_state=42)
kf_force = cross_val_score(lr, x, y, cv=kf, scoring='r2')
print("K-Fold Cross-Validation R² Scores:", kf_force*100)
print("==========================================")

kf = KFold(n_splits=5, shuffle=True, random_state=42)
kf_force = cross_val_score(lasso, x, y, cv=kf, scoring='r2')
print("K-Fold Cross-Validation Lasso R² Scores:", kf_force*100)
print("==========================================")

kf = KFold(n_splits=5, shuffle=True, random_state=42)
kf_force = cross_val_score(ridge, x, y, cv=kf, scoring='r2')
print("K-Fold Cross-Validation Ridge R² Scores:", kf_force*100)
print("==========================================")


kf = KFold(n_splits=5, shuffle=True, random_state=42)
kf_force = cross_val_score(elastic, x, y, cv=kf, scoring='r2')
print("K-Fold Cross-Validation ElasticNet R² Scores:", kf_force*100)
print("==========================================") 

#loo = LeaveOneOut()
#loo_force = cross_val_score(lr, x, y, cv=loo, scoring='r2')
#print("Leave-One-Out Cross-Validation R² Scores:", loo_force*100)
# loo = LeaveOneOut()
#loo_force = cross_val_score(lr, x, y, cv=loo, scoring='neg_mean_absolute_error')
#print("Leave-One-Out Cross-Validation R² Scores:", loo_force*100)
  



print("===================== DECEMBER -07 =====================")

df = pd.read_csv('Breast_cancer_dataset.csv')
df.sample(5)
print(df)git a
print(df.info())    
print(df.describe())
df.isnull().sum()
df.drop(['id','Unnamed: 32'],axis=1,inplace=True)
print(df.info())    
print(df.sample(2))





le = LabelEncoder()
y = le.fit_transform(y)
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)
print(x_train)
print(x_test)
print("==========================================")

